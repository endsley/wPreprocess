{"cells": [{"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["#!/usr/bin/env python"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import os\n", "import sys\n", "if os.path.exists('/home/chieh/code/wPlotLib'):\n", "\tsys.path.insert(0,'/home/chieh/code/wPlotLib')\n", "if os.path.exists('/home/chieh/code/wuML'):\n", "\tsys.path.insert(0,'/home/chieh/code/wuML')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["import wuml\n", "import numpy as np\n", "import torch\n", "import torch.nn as nn"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This code shows how you can mix and match different networks<br>\n", "This network simultaneously minimize CE and MSE loss"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def status_printing(all_losses, epoch, lr):\n", "\t[total_loss, CE_loss, Regress_loss] = all_losses\n", "\ttxt = '\\tepoch: %d, Tloss: %.4f, CEloss: %.4f, MSELoss: %.4f, Learning Rate: %.8f'%((epoch+1), total_loss, CE_loss, Regress_loss, lr)\n", "\twuml.write_to_current_line(txt)"]}, {"cell_type": "markdown", "metadata": {}, "source": ["You can also control the behavior of the network on call"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def network_behavior_on_call(all_data, all_networks):\n", "\tnet1 = all_networks[0]\n", "\tnet2 = all_networks[1]\n", "#\n", "\t#\tthe 1st 2 items of all_data will always be X, and y\n", "\t#\tthe rest will be what you include\n", "\tX = all_data[0]\n", "\ty = all_data[1]\n", "\ty2= all_data[2]\n", "#\n", "\t\u0177\u2090 = net1(X)\n", "\t\u0177\u1d66 = net2(\u0177\u2090)\n", "#\n", "\tlabels = wuml.softmax(\u0177\u2090, turn_into_label=True)\n", "\treturn [labels, \u0177\u1d66]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def costFunction(all_data, all_networks):\t\n", "\tnet1 = all_networks[0]\n", "\tnet2 = all_networks[1]\n", "#\n", "\t#\tthe 1st 3 items of all_data will always be X, y, index\n", "\t#\tthe rest will be what you include\n", "\tX = all_data[0]\n", "\ty = all_data[1]\n", "\tindx = all_data[2]\n", "\ty2= all_data[3]\n", "#\n", "\t# run data through the networks\n", "\t\u0177\u2090 = net1(X)\n", "\t\u0177\u1d66 = net2(\u0177\u2090)\n", "#\n", "\tCE_loss = wuml.CrossEntropyLoss(y, \u0177\u2090)\n", "\tRegress_loss = wuml.MSELoss(y2, \u0177\u1d66)\n", "\ttotal_loss = 0.1*CE_loss + Regress_loss\n", "#\n", "\treturn [total_loss, CE_loss, Regress_loss]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["def optimizer_steps_order(all_optimizers):\n", "\t#\tThe optimizers are in the order of the network structure you originally defined\n", "\topt1 = all_optimizers[0]\n", "\topt2 = all_optimizers[1]\n", "#\n", "\topt2.step()\n", "\topt1.step()"]}, {"cell_type": "markdown", "metadata": {}, "source": ["This data has both regression and classification labels (3 classes)<br>\n", "the network will train on both labels by<br>\n", "\tusing the 1st network to get 3 softmax outputs, <br>\n", "\tfrom the 1st network, it will connect to the 2nd network, <br>\n", "\t\texpand to width of 5 and compress down to 1 for regression"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["data = wuml.wData(xpath='../../data/wine.csv', ypath='../../data/wine_label.csv', \n", "\t\t\t\t\textra_data='../../data/wine_regress_label.csv', \n", "\t\t\t\t\tpreprocess_data='center and scale', \n", "\t\t\t\t\t batch_size=16, label_type='discrete')\n", "Y2 = data.extra_data_dictionary['numpy'][0]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["netStructureList = []\n", "netStructureList.append([(100,'relu'),(3,'none')])\n", "netStructureList.append([(50,'relu'),(1,'none')])\n", "netInputDimList = [13, 3]"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["cNet = wuml.combinedNetwork(data, netStructureList, netInputDimList, costFunction, \n", "\t\t\t\t\t\t\toptimizer_steps_order=optimizer_steps_order,\n", "\t\t\t\t\t\t\tmax_epoch=10, on_new_epoch_call_back=status_printing,\n", "\t\t\t\t\t\t\tnetwork_behavior_on_call=network_behavior_on_call,\n", "\t\t\t\t\t\t\tY_dataType=torch.LongTensor, extra_dataType=[torch.FloatTensor]) \n", "cNet.fit()\n", "[labels, \u0177\u1d66] = cNet(data)\n", "import pdb; pdb.set_trace()\n", "#\tNote that we will save this network for later use, check load_use_network.py file \n", "wuml.save_torch_network(cNet, './ComplexNet.pk')"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["CR = wuml.summarize_classification_result(data.Y, labels)\n", "#wuml.jupyter_print('\\nAccuracy : %.3f\\n\\n'%CR.avg_error())"]}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ["SR = wuml.summarize_regression_result(Y2, \u0177\u1d66)\n", "Reg_result = SR.true_vs_predict(print_out=False)\n", "wuml.jupyter_print(Reg_result, display_all_rows=True)"]}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.6.4"}}, "nbformat": 4, "nbformat_minor": 2}