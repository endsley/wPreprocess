{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "660da4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Info:\n",
      "\tLearning rate: 0.001\n",
      "\tMax number of epochs: 150\n",
      "\tCost Function: mse\n",
      "\tTrain Loop Callback: None\n",
      "\tCuda Available: True\n",
      "\tNetwork Structure\n",
      "\t\tLinear(in_features=4, out_features=100, bias=True) , relu\n",
      "\t\tLinear(in_features=100, out_features=100, bias=True) , relu\n",
      "\t\tLinear(in_features=100, out_features=1, bias=True) , none\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d5cdce8dff240b2b4e2adc89a9d051a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice that since x1 and x2 can be negative, we get both negative and positive influence.\n",
      "This is not correct since they should only have positive influence.\n",
      "[[  5.5714  -0.608    0.8444 -37.7602]\n",
      " [  1.696    1.258    0.2566   0.    ]\n",
      " [  3.81    -1.1233   0.7506 -41.8313]\n",
      " [  8.516    0.6756   1.1793 -11.7473]\n",
      " [  6.329   -0.0741   1.0796 -40.7762]\n",
      " [ -3.9921  -3.0936   0.2372 -39.5582]\n",
      " [  4.2476   0.773    1.2367 -13.0493]\n",
      " [ -0.4727  -0.86     0.0213 -39.7116]\n",
      " [ -0.3629  -2.52     0.1488 -40.6869]\n",
      " [  1.513   -2.0998   0.0921 -40.9965]\n",
      " [  0.6937   0.4914   0.4612 -12.5117]\n",
      " [  4.9272  -1.0815   0.1559 -41.2271]\n",
      " [  2.9545  -0.0215   0.4478 -27.6767]\n",
      " [  0.4126  -1.6826   0.1907 -41.1262]\n",
      " [  1.1429  -3.0555   0.0392 -32.9816]\n",
      " [  1.6646   0.3132   0.9186 -12.5198]\n",
      " [  5.5249  -1.1836   0.7384 -41.4673]\n",
      " [ -1.0058   0.0345   0.3856 -12.3271]\n",
      " [  1.0319  -0.6716   0.2569 -41.1145]\n",
      " [ -3.1466  -2.8786   0.0401 -39.3353]\n",
      " [-11.2182  -2.0143  -0.0569 -37.3623]\n",
      " [  2.602   -1.4833   0.6826 -41.7618]\n",
      " [  3.2593  -1.6424   0.3292 -41.5102]\n",
      " [ -2.9608  -2.826    0.2859 -39.9235]\n",
      " [  6.8554  -0.2411   0.2127 -40.222 ]\n",
      " [ -6.1828  -2.9969   0.1167 -38.7354]\n",
      " [  0.1905  -0.9081   0.2933 -26.9624]\n",
      " [ -0.6063  -2.1807   0.0576 -40.4254]\n",
      " [  5.4751   0.5291   1.2391   0.    ]\n",
      " [  5.7253   0.6386   0.0444 -12.2823]]\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python\n",
    "import wuml\n",
    "\n",
    "\n",
    "##\tWe generated a synthetic data for regression with 4 dimensions where\n",
    "##\tx1 x2 has positive influence\n",
    "##\tx3 has no influence\n",
    "##\tx4 has negative influence\n",
    "##\n",
    "##\tx1 has normal distribution\n",
    "##\tx2 is exponential distribution but minus 2 so it could be negative\n",
    "##\tx3 is uniform but shouldn't matter\n",
    "##\tx4 is categorical distribution.\n",
    "\n",
    "\n",
    "data = wuml.wData(xpath='../../data/shap_regress_example_mix_distributions.csv', batch_size=20, \n",
    "\t\t\t\t\tlabel_type='continuous', label_column_name='label', row_id_with_label=0)\n",
    "\n",
    "\n",
    "\n",
    "#\tExample 1\n",
    "EXP = wuml.explainer(data, \tloss='mse',\t\t# This will create a network for regression and explain instance wise \n",
    "\t\t\t\t\t\tnetworkStructure=[(100,'relu'),(100,'relu'),(1,'none')], \n",
    "\t\t\t\t\t\tmax_epoch=150, learning_rate=0.001, print_network_training_status=False)\n",
    "\n",
    "# Show the explanation results\n",
    "explanation = EXP(data)\t# outputs the weight importance\n",
    "print('Notice that since x1 and x2 can be negative, we get both negative and positive influence.')\n",
    "print('This is not correct since they should only have positive influence.')\n",
    "print(explanation)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ef914a09",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Info:\n",
      "\tLearning rate: 0.001\n",
      "\tMax number of epochs: 150\n",
      "\tCost Function: mse\n",
      "\tTrain Loop Callback: None\n",
      "\tCuda Available: True\n",
      "\tNetwork Structure\n",
      "\t\tLinear(in_features=4, out_features=100, bias=True) , relu\n",
      "\t\tLinear(in_features=100, out_features=100, bias=True) , relu\n",
      "\t\tLinear(in_features=100, out_features=1, bias=True) , none\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "75d257f175ad4ffc8e67b92a84ba9dfc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Notice that centering does not help since x1, x2, x4 can be both positive and negative, which is not correct.\n",
      "[[ -0.8643   4.4328  -3.1433 -11.62  ]\n",
      " [ -0.1604   1.8543  -2.9471  22.8934]\n",
      " [  0.832   -3.0174  -6.4843 -12.1667]\n",
      " [  0.2336  -1.1947  -0.1282  17.9027]\n",
      " [ -0.6752   3.2985  -7.1346 -12.0999]\n",
      " [ -6.7101  -8.1003   0.1931 -12.5448]\n",
      " [  1.2718   2.0287  -3.5312  14.9719]\n",
      " [ -2.6718   2.8608  -7.9017 -13.4347]\n",
      " [ -2.1916  -5.4622  -1.9146 -14.3809]\n",
      " [ -0.1149  -6.3149  -4.6145 -14.4522]\n",
      " [ -1.5148  -3.0222  -0.8517  17.4442]\n",
      " [  2.145   -2.9525  -4.5327 -14.2326]\n",
      " [  0.978    0.8465  -1.2136   5.8853]\n",
      " [ -1.2423  -1.8821  -0.1427 -14.6745]\n",
      " [  0.0028  -1.3158  -5.0155 -11.0955]\n",
      " [ -0.4376  -5.6956  -2.5139  16.3149]\n",
      " [  1.2316  -5.4971  -0.1597 -14.0195]\n",
      " [ -3.6907  -5.1446  -1.2996  17.4586]\n",
      " [ -0.4266   2.7146   0.2481 -14.4017]\n",
      " [ -6.3501  -4.4903  -5.8334 -13.3131]\n",
      " [-20.2453  -1.2556   0.6777 -11.3635]\n",
      " [  0.4882  -4.8477  -4.7376 -12.3253]\n",
      " [  1.3422  -6.5227  -1.0975 -14.8337]\n",
      " [ -5.1463  -7.351   -0.1478 -12.5806]\n",
      " [ -0.1512   2.3537  -3.7559 -13.3291]\n",
      " [-10.2981  -6.8809  -0.6546 -11.8918]\n",
      " [ -1.9849  -5.7744  -1.5115   5.8118]\n",
      " [ -2.6557  -2.988   -3.8671 -14.128 ]\n",
      " [  1.6496   3.009   -0.6324  19.7957]\n",
      " [  2.6094  -4.939   -5.1532  19.4692]]\n"
     ]
    }
   ],
   "source": [
    "#\tExample 2\n",
    "Cdata = wuml.center_and_scale(data)\n",
    "EXP2 = wuml.explainer(Cdata, \tloss='mse',\t\t# This will create a network for regression and explain instance wise \n",
    "\t\t\t\t\t\tnetworkStructure=[(100,'relu'),(100,'relu'),(1,'none')], \n",
    "\t\t\t\t\t\tmax_epoch=150, learning_rate=0.001, print_network_training_status=False)\n",
    "\n",
    "# Show the explanation results\n",
    "explanation = EXP2(Cdata)\t# outputs the weight importance\n",
    "print('Notice that centering does not help since x1, x2, x4 can be both positive and negative, which is not correct.')\n",
    "print(explanation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6711014a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network Info:\n",
      "\tLearning rate: 0.001\n",
      "\tMax number of epochs: 600\n",
      "\tCost Function: mse\n",
      "\tTrain Loop Callback: None\n",
      "\tCuda Available: True\n",
      "\tNetwork Structure\n",
      "\t\tLinear(in_features=4, out_features=600, bias=True) , relu\n",
      "\t\tLinear(in_features=600, out_features=600, bias=True) , relu\n",
      "\t\tLinear(in_features=600, out_features=600, bias=True) , relu\n",
      "\t\tLinear(in_features=600, out_features=1, bias=True) , none\n",
      "\n",
      "Avg error: 0.0547\n",
      "\n",
      "['y' 'Å·']\n",
      "[-30.88 -31.  ]\n",
      "[  0.9    0.95]\n",
      "[-40.3  -40.22]\n",
      "[ -3.22  -3.14]\n",
      "[-35.01 -34.83]\n",
      "[-47.01 -46.8 ]\n",
      "[ -6.81  -6.77]\n",
      "[-43.36 -43.35]\n",
      "[-43.91 -43.93]\n",
      "[-42.48 -42.45]\n",
      "[-11.22 -11.2 ]\n",
      "[-38.34 -38.37]\n",
      "[-22.26 -22.23]\n",
      "[-42.91 -42.89]\n",
      "[-36.14 -36.12]\n",
      "[-10.87 -10.84]\n",
      "[-38.87 -38.96]\n",
      "[-12.38 -12.34]\n",
      "[-41.63 -41.61]\n",
      "[-46.63 -46.64]\n",
      "[-52.6  -52.56]\n",
      "[-41.44 -41.48]\n",
      "[-41.15 -41.09]\n",
      "[-46.21 -46.25]\n",
      "[-33.74 -33.72]\n",
      "[-48.25 -48.3 ]\n",
      "[-25.57 -25.53]\n",
      "[-44.15 -44.2 ]\n",
      "[  6.88   6.97]\n",
      "[ -7.29  -7.21]\n",
      "\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fac9aead0afa4d46b274f4a8d59d85f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/30 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "If we map all the data into the range of [0,1], notice that x1, x2, x4 all have the correct attribution sign\n",
      "We noticed that it requires a larger network, and longer training time, but it gives better attributions.\n",
      "[[ 13.7853   1.092   -0.9513 -43.5258]\n",
      " [  7.2627  -2.742    0.4676  -2.6335]\n",
      " [  8.5319  -1.4158  -0.8984 -45.0424]\n",
      " [ 11.4175  -1.1966   0.9138 -12.8759]\n",
      " [ 12.6628  -0.3036  -1.5066 -44.2844]\n",
      " [  2.3451  -2.1981   0.3938 -45.9433]\n",
      " [ 10.892   -2.2991  -0.8539 -13.1138]\n",
      " [  4.8875  -2.189    0.0246 -44.6758]\n",
      " [  4.9128  -2.0576   0.867  -46.2521]\n",
      " [  5.8633  -1.3533   0.5028 -46.0646]\n",
      " [  5.6752  -2.7816   1.2726 -13.9708]\n",
      " [  8.9038  -0.8214   0.3208 -45.369 ]\n",
      " [  7.3389  -2.7005   0.0387 -25.505 ]\n",
      " [  6.2463  -2.4337   0.5396 -45.8414]\n",
      " [  8.0354   0.7367   0.0338 -43.5303]\n",
      " [  6.5469  -2.0901   0.0591 -13.9546]\n",
      " [  8.7763  -1.1814   0.4605 -45.6122]\n",
      " [  4.4612  -2.6167   1.2697 -14.0512]\n",
      " [  7.3768  -2.408   -0.0843 -45.0906]\n",
      " [  2.5573  -2.3905   0.3641 -45.7756]\n",
      " [  0.3681  -4.5489  -0.9126 -46.0622]\n",
      " [  7.2945  -1.5294  -0.5711 -45.2773]\n",
      " [  7.0948  -1.3681   0.6358 -46.0485]\n",
      " [  3.0088  -2.2414   0.0965 -45.7152]\n",
      " [ 11.5664   0.4354   0.3569 -44.6795]\n",
      " [  1.4122  -2.5265  -0.3954 -45.3935]\n",
      " [  4.5003  -2.8522   0.6092 -26.3879]\n",
      " [  4.8401  -2.3388   0.6369 -45.9392]\n",
      " [ 12.2117  -1.2173  -0.168   -2.4526]\n",
      " [  8.454   -1.1945   0.1099 -13.1749]]\n"
     ]
    }
   ],
   "source": [
    "#\tExample 3\n",
    "Udata = wuml.use_reverse_cdf_to_map_data_between_0_and_1(data, output_type_name='wData')\n",
    "EXP3 = wuml.explainer(Udata, \tloss='mse',\t\t# This will create a network for regression and explain instance wise \n",
    "\t\t\t\t\t\tnetworkStructure=[(600,'relu'),(600,'relu'),(600,'relu'),(1,'none')], \n",
    "\t\t\t\t\t\tmax_epoch=600, learning_rate=0.001, print_network_training_status=False)\n",
    "\n",
    "# Show the regression results\n",
    "Å¶ = EXP3.net(Udata, output_type='ndarray')\n",
    "SR_train = wuml.summarize_regression_result(Udata.Y, Å¶)\n",
    "print(SR_train.true_vs_predict())\n",
    "\n",
    "# Show the explanation results\n",
    "explanation = EXP3(Udata)\t# outputs the weight importance\n",
    "print('If we map all the data into the range of [0,1], notice that x1, x2, x4 all have the correct attribution sign')\n",
    "print('We noticed that it requires a larger network, and longer training time, but it gives better attributions.')\n",
    "print(explanation)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ae08dfd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
